<!doctype html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Assistente Virtual por Áudio</title>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap"
      rel="stylesheet"
    />

    <style>
      :root {
        --bg: #18181b;
        --surface: #27272a;
        --text: #e4e4e7;
        --text2: #a1a1aa;
        --border: rgba(255, 255, 255, 0.15);
        --card: rgba(255, 255, 255, 0.2);
        --primary: #2dd4bf;
        --primary2: #14b8a6;
        --disabled: #3f3f46;
        --ok: #4caf50;
        --rec: #f44336;
        --speak: #2196f3;
        --err: #f43f5e;
        --errbg: rgba(244, 63, 94, 0.15);
        --infobg: rgba(45, 212, 191, 0.1);
        --r: 12px;
        font-family:
          Inter,
          system-ui,
          -apple-system,
          Segoe UI,
          Roboto,
          sans-serif;
      }
      html {
        background: var(--bg);
        color: var(--text);
      }
      body {
        margin: 0;
        padding: 16px;
        min-height: 100vh;
        display: flex;
        align-items: center;
        justify-content: center;
      }
      .app {
        width: 100%;
        max-width: 520px;
        background: var(--surface);
        border: 1px solid var(--card);
        border-radius: var(--r);
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.25);
        overflow: hidden;
      }
      .head {
        padding: 22px 24px;
        border-bottom: 1px solid var(--card);
        text-align: center;
      }
      .head h1 {
        margin: 0;
        font-size: 18px;
        font-weight: 600;
      }
      .main {
        padding: 28px 24px;
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 18px;
      }
      .speaking {
        display: none;
        gap: 4px;
        height: 50px;
        align-items: center;
        justify-content: center;
      }
      .wave {
        width: 4px;
        border-radius: 999px;
        background: var(--speak);
        animation: wave 1.5s ease-in-out infinite;
      }
      .wave:nth-child(1) {
        height: 16px;
        animation-delay: 0s;
      }
      .wave:nth-child(2) {
        height: 24px;
        animation-delay: 0.2s;
      }
      .wave:nth-child(3) {
        height: 34px;
        animation-delay: 0.4s;
      }
      .wave:nth-child(4) {
        height: 20px;
        animation-delay: 0.6s;
      }
      @keyframes wave {
        0%,
        40%,
        100% {
          transform: scaleY(0.4);
        }
        20% {
          transform: scaleY(1);
        }
      }

      .mic {
        width: 82px;
        height: 82px;
        border: 0;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        transition: 0.2s ease;
        user-select: none;
        background: var(--disabled);
      }
      .mic.enabled {
        background: var(--ok);
      }
      .mic.recording {
        background: var(--rec);
        animation: pulse 1.5s ease-in-out infinite;
      }
      @keyframes pulse {
        0%,
        100% {
          transform: scale(1);
        }
        50% {
          transform: scale(1.08);
        }
      }
      .mic:disabled {
        cursor: not-allowed;
        opacity: 0.7;
      }

      .status {
        width: 100%;
        padding: 12px;
        border-radius: 10px;
        text-align: center;
        font-size: 12px;
        font-weight: 500;
        background: var(--infobg);
        color: var(--primary);
        border: 1px solid rgba(45, 212, 191, 0.25);
      }
      .status.error {
        background: var(--errbg);
        color: var(--err);
        border: 1px solid rgba(244, 63, 94, 0.35);
      }
      .hint {
        width: 100%;
        color: var(--text2);
        font-size: 12px;
        line-height: 1.45;
      }
      code {
        background: rgba(255, 255, 255, 0.08);
        padding: 2px 6px;
        border-radius: 6px;
      }
    </style>
  </head>

  <body>
    <div class="app">
      <div class="head">
        <h1>Assistente Virtual por Áudio</h1>
      </div>

      <div class="main">
        <div class="speaking" id="speaking">
          <div class="wave"></div>
          <div class="wave"></div>
          <div class="wave"></div>
          <div class="wave"></div>
        </div>

        <button class="mic" id="micBtn" disabled title="Gravar / Parar">
          <svg
            width="34"
            height="34"
            viewBox="0 0 24 24"
            fill="none"
            stroke="white"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
          >
            <path
              d="M12 2a3 3 0 0 0-3 3v6a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3z"
            ></path>
            <path d="M19 10v1a7 7 0 0 1-14 0v-1"></path>
            <line x1="12" y1="19" x2="12" y2="23"></line>
            <line x1="8" y1="23" x2="16" y2="23"></line>
          </svg>
        </button>

        <div class="status" id="status">Aguardando...</div>

        <div class="hint">
          Backend fixo:<br />
          POST: <code>https://n8n.oficinahub.xyz/webhook/speakwebpost</code
          ><br />
          GET:
          <code
            >https://n8n.oficinahub.xyz/webhook/speakwebget?id=&lt;id&gt;</code
          >
        </div>
      </div>
    </div>

    <script>
      // URLs fixas (do seu n8n)
      const POST_URL = "https://n8n.oficinahub.xyz/webhook/speakwebpost";
      const GET_URL_BASE = "https://n8n.oficinahub.xyz/webhook/speakwebget";

      const micBtn = document.getElementById("micBtn");
      const statusEl = document.getElementById("status");
      const speakingEl = document.getElementById("speaking");

      let isRecording = false;
      let mediaRecorder = null;
      let audioChunks = [];

      function setStatus(text, isError = false) {
        statusEl.textContent = text;
        statusEl.classList.toggle("error", !!isError);
      }

      function sleep(ms) {
        return new Promise((r) => setTimeout(r, ms));
      }

      function showSpeaking(on) {
        speakingEl.style.display = on ? "flex" : "none";
      }

      function blobToBase64(blob) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader();
          reader.onloadend = () => {
            const base64 = String(reader.result || "").split(",")[1] || "";
            resolve(base64);
          };
          reader.onerror = reject;
          reader.readAsDataURL(blob);
        });
      }

      // Espera até o GET realmente devolver áudio (não JSON/0 bytes)
      async function waitUntilAudioReady(
        getUrl,
        controller,
        tries = 20,
        delayMs = 1500,
      ) {
        let last = "";

        for (let i = 1; i <= tries; i++) {
          setStatus(`Aguardando MP3... ${i}/${tries}`);

          const res = await fetch(getUrl, {
            method: "GET",
            cache: "no-store",
            signal: controller.signal,
          });

          const ct = (res.headers.get("content-type") || "").toLowerCase();
          const buf = await res.arrayBuffer(); // lê bytes puros [web:111]
          const size = buf.byteLength;

          console.log(
            "[Front] GET status:",
            res.status,
            "Content-Type:",
            ct,
            "bytes:",
            size,
          );

          // Pronto: veio áudio e veio payload de verdade
          if (res.ok && ct.startsWith("audio/") && size > 1000) {
            return; // não precisa retornar blob, vamos tocar por URL
          }

          // Ainda não pronto / resposta errada
          last = `status=${res.status} ct=${ct} bytes=${size}`;
          await sleep(delayMs);
        }

        throw new Error(`MP3 não ficou pronto a tempo (${last}).`);
      }

      // Toca direto pelo endpoint GET (evita problemas com blob:)
      async function playFromUrl(getUrl) {
        setStatus("Tocando resposta...");
        showSpeaking(true);

        const a = new Audio();
        a.preload = "auto";
        a.src = getUrl;

        a.onended = () => {
          showSpeaking(false);
          setStatus("Pronto para gravar.");
        };

        a.onerror = () => {
          showSpeaking(false);
          setStatus("Erro ao tocar áudio (player falhou).", true);
        };

        try {
          // play() retorna Promise e pode ser bloqueado por política do browser [web:105]
          await a.play();
        } catch (e) {
          console.error("Falha ao dar play:", e);
          showSpeaking(false);
          setStatus(
            "Erro ao tocar áudio (autoplay bloqueado ou erro no arquivo).",
            true,
          );
        }
      }

      async function sendAudioToBackend(audioBlob) {
        setStatus("Convertendo áudio...");
        const base64 = await blobToBase64(audioBlob);

        console.log("[Front] Áudio convertido para Base64");

        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), 120000);

        try {
          setStatus("Enviando para o backend (POST)...");
          console.log("[Front] POST =>", POST_URL);

          const postRes = await fetch(POST_URL, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ base64 }),
            signal: controller.signal,
          });

          const postText = await postRes.text().catch(() => "");
          console.log(
            "[Front] POST status:",
            postRes.status,
            postRes.statusText,
          );
          console.log("[Front] POST body:", postText);

          if (!postRes.ok)
            throw new Error(`POST falhou: ${postRes.status} ${postText}`);

          let id = null;
          try {
            id = JSON.parse(postText)?.id;
          } catch (_) {}

          if (!id) throw new Error('POST não retornou JSON com "id".');

          const getUrl = `${GET_URL_BASE}?id=${encodeURIComponent(id)}`;
          console.log("[Front] GET =>", getUrl);

          // Espera de prontidão (se o arquivo ainda não existe, o GET tende a devolver JSON/0 bytes no seu caso)
          await waitUntilAudioReady(getUrl, controller, 30, 1500);

          clearTimeout(timeoutId);

          // Toca por URL normal
          await playFromUrl(getUrl);
        } catch (e) {
          clearTimeout(timeoutId);
          if (e?.name === "AbortError") {
            setStatus("Erro: Timeout geral do processo.", true);
            return;
          }
          console.error("[Front] Erro:", e);
          setStatus(
            `Erro: ${e?.message || "Falha ao contatar o backend."}`,
            true,
          );
        }
      }

      async function startRecording() {
        if (isRecording) return;

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          audioChunks = [];

          mediaRecorder = new MediaRecorder(stream);
          isRecording = true;

          mediaRecorder.ondataavailable = (ev) => audioChunks.push(ev.data);

          mediaRecorder.onstop = () => {
            isRecording = false;
            micBtn.classList.remove("recording");
            micBtn.classList.add("enabled");

            const blob = new Blob(audioChunks, { type: "audio/webm" });
            setStatus("Processando...");
            sendAudioToBackend(blob).finally(() =>
              stream.getTracks().forEach((t) => t.stop()),
            );
          };

          mediaRecorder.start();
          micBtn.classList.add("recording");
          micBtn.classList.remove("enabled");
          setStatus("Gravando... clique para parar.");
        } catch (e) {
          console.error("Erro ao acessar microfone:", e);
          setStatus("Erro: permissão ao microfone negada.", true);
          isRecording = false;
        }
      }

      function stopRecording() {
        if (!isRecording || !mediaRecorder) return;
        mediaRecorder.stop();
      }

      // Init
      (function init() {
        const ok = navigator.mediaDevices?.getUserMedia && window.MediaRecorder;
        if (!ok) {
          setStatus("Erro: seu navegador não suporta gravação de áudio.", true);
          return;
        }
        micBtn.disabled = false;
        micBtn.classList.add("enabled");
        setStatus("Pronto para gravar.");

        micBtn.addEventListener("click", () => {
          if (isRecording) stopRecording();
          else startRecording();
        });
      })();

      function playResponseAudio(_) {
        // Compatibilidade: agora tocamos por URL, não por blob
        throw new Error("Função antiga. Use playFromUrl(getUrl).");
      }
    </script>
  </body>
</html>
